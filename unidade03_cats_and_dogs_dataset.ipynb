{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardodacostasoares/Data_Science/blob/master/unidade03_cats_and_dogs_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcCHeYYyapv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1e8223-671b-4dd1-fe5e-10bfe54bf316"
      },
      "source": [
        "# check whether GPU is provided\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Sun Apr 16 16:13:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ghBxO0SuPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3b350d-ebb7-4cae-caad-beacb398eb5b"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O cats_and_dogs_filtered.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-16 16:13:17--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘cats_and_dogs_filtered.zip’\n",
            "\n",
            "cats_and_dogs_filte 100%[===================>]  65.43M   157MB/s    in 0.4s    \n",
            "\n",
            "2023-04-16 16:13:17 (157 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AwU0DC6eocm"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BxhK1wTiFBu"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = 'data/cats_and_dogs_filtered/'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "# test_dir = os.path.join(base_dir, 'test')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8PP7lcrgGnq"
      },
      "source": [
        "**Building our network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FopSstCWeq0A"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFEiOv8Zgj7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a373a15-a60d-4e26-fecd-147713482811"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9cP0Je9glDf"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1wziOiSgtiU"
      },
      "source": [
        "**Data preprocessing**\n",
        "\n",
        "Devemos converter os dados em tensores de ponto flutuante. Devemos seguir as seguintes etapas:\n",
        "\n",
        "Leia os arquivos de imagem.\n",
        "Decodifique em pixels RGB\n",
        "Converta-os em tensores de ponto flutuante.\n",
        "Rescale de cada pixels de (0 a 255) para [0, 1]\n",
        "\n",
        "O keras.preprocessing.image contém a classe ImageDataGenerator, que permite configurar geradores Python que podem transformar automaticamente arquivos de imagem em disco em lotes de tensores pré-processados. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXYUCmOcgnDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fefe62-3cad-4495-a638-fa5dad44df08"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8GgSWGQKf7r"
      },
      "source": [
        "Vamos dar uma olhada no formato dos arquivos gerados pelo python\n",
        "\n",
        "Foram produzidos batches de imagens RGB de 150x150 (shape (20, 150, 150, 3)) e labels binárias (shape (20,))\n",
        "\n",
        "20 é o número de amostras em cada batch (o tamanho do batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wccSRTyNi9GJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658e6d2b-8364-4b9d-9f88-0d196d5347ca"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data batch shape: (20, 150, 150, 3)\n",
            "labels batch shape: (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob2YuvNVLPeX"
      },
      "source": [
        "**Treinando o modelo**\n",
        "\n",
        "Vamos ajustar nosso modelo aos dados usando o gerador, usando o método **fit_generator**\n",
        "\n",
        "train_generator: (primeiro argumento) produzirá batches indefinidamente. \n",
        "\n",
        "Como os dados estão sendo gerados infinitamente, o gerador precisa saber por exemplo quantas amostras extrair do gerador antes de declarar uma época.\n",
        "\n",
        "Assim, usamos o **steps_per_epoch** para que, depois de extrair \"steps_per_epoch\" batches do gerador, o model.fit irá para a próxima época. Neste caso, cada batch possui 20 amostras, portanto, serão necesssário 100 batches até atingirmos o objetivo de 2000 amostras.  \n",
        "\n",
        "**validation_data**: pode ser um gerador (como neste caso) e portanto, temos que fornecer o argumento **validation_steps** pois o gerador irá gerar dados infinitamente. O argumento validation_steps determina quantos batches serão extraídos do gerador Python de validação para a avaliação do modelo (50 pois nosso conjunto de validação possui 1000 amostras). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkRFxkHhjPZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8d6703-26fa-4eef-8e14-7bf55a003188"
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-a7acfc8093a4>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 21s 98ms/step - loss: 0.6898 - acc: 0.5265 - val_loss: 0.7167 - val_acc: 0.5000\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6700 - acc: 0.5810 - val_loss: 0.6439 - val_acc: 0.6450\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.6362 - acc: 0.6435 - val_loss: 0.6166 - val_acc: 0.6840\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5977 - acc: 0.6780 - val_loss: 0.6167 - val_acc: 0.6440\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.5743 - acc: 0.6940 - val_loss: 0.6233 - val_acc: 0.6420\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.5463 - acc: 0.7200 - val_loss: 0.5588 - val_acc: 0.7140\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5223 - acc: 0.7345 - val_loss: 0.5503 - val_acc: 0.7170\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5047 - acc: 0.7390 - val_loss: 0.5512 - val_acc: 0.7160\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4718 - acc: 0.7820 - val_loss: 0.6520 - val_acc: 0.6520\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.4673 - acc: 0.7680 - val_loss: 0.5449 - val_acc: 0.7290\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.4388 - acc: 0.7890 - val_loss: 0.5446 - val_acc: 0.7220\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4151 - acc: 0.8120 - val_loss: 0.5317 - val_acc: 0.7390\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.3958 - acc: 0.8145 - val_loss: 0.5307 - val_acc: 0.7410\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3748 - acc: 0.8355 - val_loss: 0.5208 - val_acc: 0.7460\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.3562 - acc: 0.8390 - val_loss: 0.5427 - val_acc: 0.7360\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3402 - acc: 0.8575 - val_loss: 0.5388 - val_acc: 0.7550\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3042 - acc: 0.8710 - val_loss: 0.5453 - val_acc: 0.7550\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2882 - acc: 0.8810 - val_loss: 0.7030 - val_acc: 0.7060\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2685 - acc: 0.8870 - val_loss: 0.5836 - val_acc: 0.7360\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2415 - acc: 0.9065 - val_loss: 0.5682 - val_acc: 0.7500\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2242 - acc: 0.9110 - val_loss: 0.5640 - val_acc: 0.7570\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2006 - acc: 0.9280 - val_loss: 0.6206 - val_acc: 0.7510\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1849 - acc: 0.9275 - val_loss: 0.5785 - val_acc: 0.7600\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1657 - acc: 0.9415 - val_loss: 0.6739 - val_acc: 0.7280\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.1449 - acc: 0.9510 - val_loss: 0.6900 - val_acc: 0.7390\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.1327 - acc: 0.9555 - val_loss: 0.6789 - val_acc: 0.7480\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.1187 - acc: 0.9595 - val_loss: 0.6749 - val_acc: 0.7530\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.0969 - acc: 0.9705 - val_loss: 0.7265 - val_acc: 0.7490\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.0878 - acc: 0.9720 - val_loss: 0.7305 - val_acc: 0.7510\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.0763 - acc: 0.9760 - val_loss: 0.7207 - val_acc: 0.7730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiAlEpNHjw_I"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2aiwWLYj16K"
      },
      "source": [
        "Vamos plotar a loss e a acurácia do modelo sobre os dados de treinamento e validação durante o treinamento:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2zzKgwhj2ZR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FPGbsB1QUNq"
      },
      "source": [
        "Observe que a acurácia dos dados de treinamento aumenta linearmente ao longo do tempo até atingir quase 100% (e validação não passa de 70%).\n",
        "\n",
        "A validation loss atinge seu mínimo depois de apenas cinco épocas, e a train loss continua diminuindo linearmente até atingir quase 0.\n",
        "\n",
        "Como temos apenas poucas amostras de treinamento (2000), o maior risco é de overfitting (poderíamos resolver o problema com dropout). \n",
        "\n",
        "No entanto, usaremos uma técnica muito como para visão computacional que pode solucionar o problema de overfitting: **data augmentation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NHVVxcYRyQH"
      },
      "source": [
        "Mas, antes de abordarmos o assunto de data augmentation, vamos aprender a realizar algumas poredições no nosso modelo treinado.\n",
        "\n",
        "**Realizando Predições**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC1mo05bSDsc"
      },
      "source": [
        "Obtendo uma imagem de exemplo usando no treinamento (veja que esta imagem já está pré-processada)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbVcfetnnHgH"
      },
      "source": [
        "data_batch, labels_batch = validation_generator[0]\n",
        "print('data batch shape:', data_batch.shape)\n",
        "print(data_batch[5].shape)\n",
        "\n",
        "x = data_batch[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkM9QWryVWRp"
      },
      "source": [
        "Observe o shape da imagem (150, 150, 3), para a predição temos que converter para um tensor 4D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50YbCvezmiOO"
      },
      "source": [
        "x = x.reshape(1, 150, 150, 3)\n",
        "\n",
        "print (x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59XlvqiLoN2v"
      },
      "source": [
        "Realizando a inferência: a loss function binary_crossentropy retorna um valor de probabilidade entre 0 e 1 para a classificação binária (cat - 0 e dog - 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eug5ibhoM7w"
      },
      "source": [
        "prob = model.predict(x)\n",
        "\n",
        "print(prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbdCqR8NuaWG"
      },
      "source": [
        "Abrindo uma imagem diretamente do diretório. Obsserve que agora a imagem não está pre-processada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqi5B3cwum0g"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "path = os.path.join(base_dir, 'validation/dogs/dog.2010.jpg')\n",
        "\n",
        "img = cv2.imread(path) \n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdbUCJxTveOh"
      },
      "source": [
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erhEMHoiVtUc"
      },
      "source": [
        "Vamos carregar a imagem usando PIL (biblioteca para processamento de imagens em Python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIBoU5wYwSN9"
      },
      "source": [
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from PIL import Image\n",
        "\n",
        "img = load_img(path, target_size=(150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tmphD7UV2k_"
      },
      "source": [
        "Rescale de cada pixels de (0 a 255) para [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFQObhcnCe83"
      },
      "source": [
        "from numpy import asarray\n",
        "\n",
        "img = asarray(img)\n",
        "\n",
        "print('Data Type: %s' % img.dtype)\n",
        "print('Min: %.3f, Max: %.3f' % (img.min(), img.max()))\n",
        "\n",
        "img = img.astype('float32')\n",
        "img /= 255.0\n",
        "\n",
        "print('Min: %.3f, Max: %.3f' % (img.min(), img.max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOFMH9UYCyk7"
      },
      "source": [
        "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDTtT8qUBU3t"
      },
      "source": [
        "prob = model.predict(x)\n",
        "\n",
        "print(prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDjAJjno_Y7S"
      },
      "source": [
        "**Usando data augmentation**\n",
        "\n",
        "O problema de overfitting foi causado por ter poucas amostras para aprender, ou seja, faz com que o modelo seja incapazes de generalizar para novos dados.\n",
        "\n",
        "Data augmentation gera mais dados de treinamento a partir de amostras existentes de treinamento, por meio de várias transformações aleatórias que produzem novas imagens. \n",
        "\n",
        "O objetivo é que, durante o treinamento, nosso modelo nunca veja exatamente a mesma imagem duas vezes. Isso ajuda o modelo a se expor a mais aspectos dos dados e a generalizar melhor.\n",
        "\n",
        "Você pude utilizar operações de processamento de imagens comuns para produzir novas amostras de dados a partir das imagens de treinamento.\n",
        "\n",
        "Acesse para exemplos:\n",
        "\n",
        "https://github.com/albumentations-team/albumentations\n",
        "\n",
        "https://github.com/codebox/image_augmentor\n",
        "\n",
        "\n",
        "No Keras, isso pode ser feito configurando várias transformações aleatórias a serem executadas nas imagens lidas pela nossa instância do ImageDataGenerator. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QODDjYgi_b95"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmfIYy6oEvpN"
      },
      "source": [
        "Estas são apenas algumas das opções disponíveis (para mais, consulte a documentação do Keras). \n",
        "\n",
        "rotation_range é um valor em graus (0-180), um intervalo no qual gira aleatoriamente as imagens.\n",
        "\n",
        "width_shift e height_shift são intervalos dentro dos quais rotaciona aleatoriamente imagens na vertical ou na horizontal.\n",
        "\n",
        "shear_range é para aplicar aleatoriamente transformações de cisalhamento.\n",
        "\n",
        "zoom_range é para ampliar aleatoriamente as imagens.\n",
        "\n",
        "horizontal_flip é para virar aleatoriamente metade das imagens horizontalmente\n",
        "\n",
        "fill_mode é a estratégia usada para preencher pixels recém-criados, que podem aparecer após uma rotação ou uma mudança de largura / altura."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgvb0ZwUFcau"
      },
      "source": [
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8yKbIT_E18q"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
        "\n",
        "# We pick one image to \"augment\"\n",
        "img_path = fnames[3]\n",
        "\n",
        "# Read the image and resize it\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "# Convert it to a Numpy array with shape (150, 150, 3)\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Reshape it to (1, 150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# The .flow() command below generates batches of randomly transformed images.\n",
        "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0:\n",
        "        break\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aufXBAbDZqrW"
      },
      "source": [
        "Se treinarmos uma nova rede usando data augmentation, a rede nunca verá duas vezes a mesma entrada. No entanto, isso pode não ser suficiente para se livrar completamente do problema de overfitting. Para isso, também adicionaremos uma camada Dropout ao modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rmrQJ7uGYg7"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKVi74nAGeSO"
      },
      "source": [
        "Treinando o modelo usando data augmentation e dropout\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBpqpt3UGfDN"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7RV09C_G2n5"
      },
      "source": [
        "model.save('cats_and_dogs_small_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eilFzqctG4AE"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr7cGIIjaWZ_"
      },
      "source": [
        "Observe que agora não estamos mais enfrentando o problema de overfitting. \n",
        "\n",
        "As curvas de treinamento estão acompanhando de perto as curvas de validação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKAiEu9aaujk"
      },
      "source": [
        "Referência: François Chollet. Deep Learning with Python. November 2017  "
      ]
    }
  ]
}